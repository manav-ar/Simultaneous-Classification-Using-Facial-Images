{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8n273iCB_MG"
   },
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import SeparableConv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "\n",
    "from keras import applications,activations\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from keras import optimizers,utils\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization,ZeroPadding2D, Input\n",
    "from keras.layers import Conv2D, Activation,MaxPooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [10,5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTK_PATHS  ={\n",
    "    'DB_PATH':'./UTKFace',\n",
    "    'MODEL_SAVED':'./model_outputs_UTK/iteration_{}',\n",
    "    'MODEL_HISTORY':'./model_outputs_UTK/model_history_{}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZbxDjTNCFGo"
   },
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.8\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "\n",
    "dataset_dict = {\n",
    "    'race_id': {\n",
    "        0: 'white', \n",
    "        1: 'black', \n",
    "        2: 'asian', \n",
    "        3: 'indian', \n",
    "        4: 'others'\n",
    "    },\n",
    "    'gender_id': {\n",
    "        0: 'male',\n",
    "        1: 'female'\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())    # (Gender: id)\n",
    "dataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())        # (Race: id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXkn8umRCPuM"
   },
   "outputs": [],
   "source": [
    "def parse_dataset(dataset_path, ext='jpg'):\n",
    "    \"\"\"\n",
    "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame\n",
    "     with the data (age, gender and sex) of all files.\n",
    "    \"\"\"\n",
    "    def parse_info_from_file(path):\n",
    "        \"\"\"\n",
    "        Parse information from a single file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            filename = os.path.split(path)[1]\n",
    "            filename = os.path.splitext(filename)[0]\n",
    "            age, gender, race, _ = filename.split('_')\n",
    "\n",
    "            return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)]\n",
    "        except Exception as ex:\n",
    "            return None, None, None\n",
    "        \n",
    "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n",
    "    \n",
    "    records = []\n",
    "    for file in files:\n",
    "        info = parse_info_from_file(file)\n",
    "        records.append(info)\n",
    "        \n",
    "    df = pd.DataFrame(records)\n",
    "    df['file'] = files\n",
    "    df.columns = ['age', 'gender', 'race', 'file']\n",
    "    \n",
    "   \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def saveModelHistory(model_history,iteration,path):\n",
    "    with open(path.format(iteration), 'wb') as fp:\n",
    "        pickle.dump(model_history, fp)\n",
    "        \n",
    "def loadModelHistory(iteration,path):\n",
    "    with open (path.format(iteration), 'rb') as fp:\n",
    "        model_history = pickle.load(fp)  \n",
    "    return model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ybscrdgBCWxr",
    "outputId": "56d48a3a-ee05-4911-daa9-ca9a31fc6dae"
   },
   "outputs": [],
   "source": [
    "df = parse_dataset(UTK_PATHS['DB_PATH'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "e3TxXvhHpVH5",
    "outputId": "f3759822-3289-4508-bbc0-32414c935ae3"
   },
   "outputs": [],
   "source": [
    "#ENCODING FOR ITER 2,3,4\n",
    "df1 = df[df['age']< 60]\n",
    "df2 = df[df['age']>= 60]\n",
    "\n",
    "df1['age'] = df1['age']//10\n",
    "df2['age'] = 6.0\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "df['age'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMRE13cQpr-i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "p = np.random.permutation(len(df))\n",
    "\n",
    "train_up_to = int(len(df) * TRAIN_TEST_SPLIT)      \n",
    "train_idx = p[:train_up_to]\n",
    "val_idx = p[train_up_to:]\n",
    "\n",
    "# converts alias to id\n",
    "df['gender_id'] = df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\n",
    "df['race_id'] = df['race'].map(lambda race: dataset_dict['race_alias'][race])\n",
    "\n",
    "            \n",
    "def preprocess_image(img_path):   # Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "    \n",
    "    im = Image.open(img_path)\n",
    "    im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "    im = np.array(im) / 255.0\n",
    "    \n",
    "    return im\n",
    "        \n",
    "def generate_imagesR(image_idx, is_training, batch_size=16):  # Used to generate a batch with images when training/validating our model.\n",
    "    \n",
    "    # arrays to store our batched data\n",
    "    images, ages, races, genders = [], [], [], []\n",
    "\n",
    "    while True:\n",
    "        for idx in image_idx:\n",
    "            person = df.iloc[idx]\n",
    "            \n",
    "            age = person['age']\n",
    "            race = person['race_id']\n",
    "            gender = person['gender_id']\n",
    "            file = person['file']\n",
    "            \n",
    "            im = preprocess_image(file)\n",
    "            \n",
    "            races.append(to_categorical(race, len(dataset_dict['race_id'])))\n",
    "            genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n",
    "            ages.append(to_categorical(age,7)) #5\n",
    "            images.append(im)\n",
    "            \n",
    "            # yielding condition\n",
    "            if len(images) >= batch_size:\n",
    "                yield np.array(images), [np.array(ages), np.array(genders), np.array(races)]\n",
    "                images, ages, genders, races = [], [], [], []\n",
    "                \n",
    "        if not is_training:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKw1rg2SE4og"
   },
   "outputs": [],
   "source": [
    "def make_default_hidden_layers(inputs):\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding=\"same\")(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = SpatialDropout2D(0.15)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = SpatialDropout2D(0.15)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_gender_branch(inputs):\n",
    "  \n",
    "    x = make_default_hidden_layers(inputs)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "  \n",
    "    x = Dense(2)(x)\n",
    "    x = Activation(\"softmax\", name=\"gender_output\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_age_branch(inputs):   \n",
    "\n",
    "    x = make_default_hidden_layers(inputs)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, kernel_regularizer=l2(0.03))(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(32)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(7)(x)\n",
    "    x = Activation(\"softmax\", name=\"age_output\")(x)  \n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_race_branch(inputs):   \n",
    "\n",
    "    x = make_default_hidden_layers(inputs)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, kernel_regularizer=l2(0.03))(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(32)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(5)(x)\n",
    "    x = Activation(\"softmax\", name=\"race_output\")(x)  \n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def assemble_modelR(width, height):\n",
    "  \n",
    "    input_shape = (height, width, 3)\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    age_branch = build_age_branch(inputs)\n",
    "    gender_branch = build_gender_branch(inputs)\n",
    "    race_branch = build_race_branch(inputs)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs = [age_branch, gender_branch, race_branch], name=\"face_net\")\n",
    "\n",
    "    return model\n",
    "    \n",
    "model = assemble_modelR(198, 198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtFNWMK011mL",
    "outputId": "23e36c15-f250-4016-e83f-e2ee68760356"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tkRERfV7CIe3",
    "outputId": "4150b6e4-6232-4afa-dec0-77413cbd2672"
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYUF1n3nyfj7"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced' ,np.array([0,1,2,3,4,5,6]) ,np.array(df['age']))\n",
    "\n",
    "class_weights = dict(zip(list(range(7)), weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "soCfKO0kBtHZ",
    "outputId": "49baed00-979c-4649-b47f-3e81eb10e520"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.002\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 7.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate      \n",
    "\n",
    "opt = Adam(lr=0.0)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "train_gen = generate_imagesR(train_idx, is_training=True, batch_size=32)\n",
    "valid_gen = generate_imagesR(val_idx, is_training=True, batch_size=32)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  'age_output': 'categorical_crossentropy', \n",
    "                  'gender_output': 'categorical_crossentropy',\n",
    "                  'race_output': 'categorical_crossentropy' },\n",
    "              metrics={\n",
    "                  'age_output': 'accuracy',  \n",
    "                  'gender_output': 'accuracy',\n",
    "                  'race_output': 'accuracy'})\n",
    "\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch = len(train_idx)//32, epochs=50  , callbacks=callbacks_list,\n",
    "                     validation_data=valid_gen, validation_steps=len(val_idx)//32,class_weight=class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_OUTPUT_PATH = './model_outputs'\n",
    "saveModelHistory(history,ITERATION)\n",
    "model.save(MODEL_OUTPUT_PATH+'/iteration_{}'.format(ITERATION)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "kKvYof9Orckk",
    "outputId": "6fdea972-c5d9-4bf7-933c-9531ec34c706"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(36, 12))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Total Loss', 'Val Total Loss'], loc='upper right')\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "plt.plot(history.history['age_output_loss'])\n",
    "plt.plot(history.history['val_age_output_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Age Loss', 'Val Age Loss'], loc='upper right')\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "plt.plot(history.history['gender_output_loss'])\n",
    "plt.plot(history.history['val_gender_output_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Gender Loss', 'Val Gender Loss'], loc='upper right')\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "plt.plot(history.history['race_output_loss'])\n",
    "plt.plot(history.history['val_race_output_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Race Loss', 'Val Race Loss'], loc='upper right')\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "plt.plot(history.history['age_output_acc'])\n",
    "plt.plot(history.history['val_age_output_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Age Accuracy', 'Val Age Accuracy'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "plt.plot(history.history['gender_output_acc'])\n",
    "plt.plot(history.history['val_gender_output_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Gender Accuracy', 'Val Gender Accuracy'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "plt.plot(history.history['race_output_acc'])\n",
    "plt.plot(history.history['val_race_output_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Race Accuracy', 'Val Race Accuracy'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,4,8)\n",
    "plt.plot(history.history['lr'])\n",
    "plt.ylabel('learning rate')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['Adaptive Learning Rate'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kBwJnbighbh"
   },
   "source": [
    "# CODE FOR SAVING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAC7roT8gfmK"
   },
   "outputs": [],
   "source": [
    "ITERATION = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelHistory(history,ITERATION,UTK_PATHS['MODEL_HISTORY'])\n",
    "model.save(UTK_PATHS['MODEL_SAVED'].format(ITERATION)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Race,Gender & Age Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
